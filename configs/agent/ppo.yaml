algo: "ppolag"
state_dependent_std: False

lagrange:
  type: pid
  positive_violation: False
  params:
    initial_value: 1.0
    kp: 1.0
    ki: 0.1
    kd: 2.0
    d_delay: 5
    alpha_p: 0.5
    alpha_d: 0.5
    cost_limit: 0
    proj: "relu"

actor_lr: 0.003
critic_lr: 0.005
lag_lr: 0.5
actor_weight_decay: 0.005
schedule: True
orthogonal_init: True
activation: "tanh"
use_beta: True

actor_dist_bound: 0  # float; if <= 0, actions are unbounded,
                      # if > 0 action range is symmetric [-bound, bound]

loss_module:
  clip_epsilon: 0.2
  entropy_coef: 0.00
  entropy_bonus: False
  critic_coef: 0.5
  gamma: 1.0
  loss_critic_type: "smooth_l1"
  normalize_advantage: True
  target_kl: 0.025
  reward_scale: 0.01
  cost_scale: 0.01

estimator:
  gamma: 1.0
  lmbda: 0.95