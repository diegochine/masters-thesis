algo: "ppolag"
state_dependent_std: False
std_dev_init: 1.0
std_dev_trainable: True

lagrange:
  type: pid
  positive_violation: False
  params:
    initial_value: 1.0
    kp: 0.01
    ki: 0.001
    kd: 0.05
    d_delay: 1
    alpha_p: 0.0
    alpha_d: 0.0
    cost_limit: 0
    proj: "relu"

actor_lr: 0.001
critic_lr: 0.001
lag_lr: 0.001
actor_weight_decay: 0.0
schedule: False
orthogonal_init: False
activation: "tanh"

actor_dist_bound: 10  # float; if <= 0, actions are unbounded,
                      # if > 0 action range is symmetric [-bound, bound]

loss_module:
  clip_epsilon: 0.2
  entropy_coef: 0.00
  entropy_bonus: False
  critic_coef: 0.5
  gamma: 1.0
  loss_critic_type: "smooth_l1"
  normalize_advantage: True
  lagrangian_delay: 20
  target_kl: 0.025
  reward_scale: 0.05
  cost_scale: 0.01

estimator:
  gamma: 1.0
  lmbda: 0.95